{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "import sys\n",
    "from abc import abstractmethod\n",
    "from typing import Dict, Optional, Tuple\n",
    "\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchsummary import summary\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "Loaded pretrained weights for efficientnet-b1\n",
      "Loaded pretrained weights for efficientnet-b2\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b4\n",
      "Loaded pretrained weights for efficientnet-b5\n",
      "Loaded pretrained weights for efficientnet-b6\n",
      "Loaded pretrained weights for efficientnet-b7\n"
     ]
    }
   ],
   "source": [
    "# AUTO = tf.data.experimental.AUTOTUNE\n",
    "# IMAGE_SIZE = [512, 512]\n",
    "# EPOCHS = 2000\n",
    "# BATCH_SIZE_PER_TPU = 8\n",
    "# BATCH_SIZE = BATCH_SIZE_PER_TPU * strategy.num_replicas_in_sync\n",
    "# FOLDERNAME = \"v2clean_sample\"\n",
    "# NUM_CLASSES = 81313\n",
    "EMB_SIZE = 512\n",
    "EFNS = [\n",
    "    EfficientNet.from_pretrained(\"efficientnet-b0\", num_classes=EMB_SIZE),\n",
    "    EfficientNet.from_pretrained(\"efficientnet-b1\"),\n",
    "    EfficientNet.from_pretrained(\"efficientnet-b2\"),\n",
    "    EfficientNet.from_pretrained(\"efficientnet-b3\"),\n",
    "    EfficientNet.from_pretrained(\"efficientnet-b4\"),\n",
    "    EfficientNet.from_pretrained(\"efficientnet-b5\"),\n",
    "    EfficientNet.from_pretrained(\"efficientnet-b6\"),\n",
    "    EfficientNet.from_pretrained(\"efficientnet-b7\", num_classes=EMB_SIZE),\n",
    "]\n",
    "EFF_VER = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AngularMarginHead(nn.Module):\n",
    "    def __init__(\n",
    "        self, feature_size: int, nb_classes: int, s: int, m: float, clip: Optional[bool] = True\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.min_allowed = math.cos(math.pi - m)\n",
    "        self.clip = clip\n",
    "\n",
    "        self._cosine = None\n",
    "        self.sine = None\n",
    "\n",
    "        self.weight = nn.parameter.Parameter(torch.Tensor(nb_classes, feature_size))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "    @property\n",
    "    def cosine(self):\n",
    "        return self._cosine\n",
    "\n",
    "    @cosine.setter\n",
    "    def cosine(self, value):\n",
    "        self._cosine = value\n",
    "        self.sine = torch.sqrt(1 - self.cosine ** 2)\n",
    "\n",
    "    @abstractmethod\n",
    "    def positive_cosine_similarity_modulator(self) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Positive cosine similarity modulator\n",
    "        \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def negative_cosine_similarity_modulator(\n",
    "        self, cosine_after_positive_modulator: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Negative cosine similarity modulator\n",
    "        \"\"\"\n",
    "\n",
    "    def forward(self, features: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        self.cosine = F.linear(F.normalize(features), F.normalize(self.weight))\n",
    "        if self.clip:\n",
    "            self.cosine = torch.clip(self.cosine, self.min_allowed, 0.99)\n",
    "\n",
    "        one_hot = torch.zeros_like(self.cosine).to(y.device)\n",
    "        one_hot.scatter_(1, y.view(-1, 1).long(), 1)\n",
    "\n",
    "        cosine_after_positive_modulator = self.positive_cosine_similarity_modulator()\n",
    "        cosine_after_negative_modulator = self.negative_cosine_similarity_modulator(\n",
    "            cosine_after_positive_modulator\n",
    "        )\n",
    "\n",
    "        output = torch.where(\n",
    "            one_hot == 1, cosine_after_positive_modulator, cosine_after_negative_modulator\n",
    "        )\n",
    "        return self.s * output\n",
    "\n",
    "\n",
    "class ArcFace(AngularMarginHead):\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_size: int,\n",
    "        nb_classes: int,\n",
    "        s: Optional[int] = 64,\n",
    "        m: Optional[float] = 0.5,\n",
    "        clip: Optional[bool] = True,\n",
    "    ) -> None:\n",
    "        super().__init__(feature_size, nb_classes, s, m, clip)\n",
    "\n",
    "    def positive_cosine_similarity_modulator(self) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Positive cosine modulator for ArcFace is: T(cos(theta)) = cos(theta + m),\n",
    "        if we expand this expression it becomes: cos(theta)*cos(m) - sin(theta)*sin(m)\n",
    "        \"\"\"\n",
    "        return self.cosine * self.cos_m - self.sine * self.sin_m\n",
    "\n",
    "    def negative_cosine_similarity_modulator(\n",
    "        self, cosine_after_positive_modulator: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        There is no modulation for negative cosine similarity in ArcFace\n",
    "        \"\"\"\n",
    "        return self.cosine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetBackbone(nn.Module):\n",
    "    def __init__(self, feature_size: int):\n",
    "        super(EfficientNetBackbone, self).__init__()\n",
    "\n",
    "        self.efficientNet = EFNS[EFF_VER]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.efficientNet(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logger():\n",
    "    logger = logging.getLogger(\"train\")\n",
    "    logger.setLevel(logging.INFO)\n",
    "    if len(logger.handlers) == 0:\n",
    "        formatter = logging.Formatter(\"%(asctime)s | %(message)s\")\n",
    "        ch = logging.StreamHandler(stream=sys.stdout)\n",
    "        ch.setFormatter(formatter)\n",
    "        logger.addHandler(ch)\n",
    "        fh = logging.handlers.WatchedFileHandler(\"data/train.log\")\n",
    "        fh.setFormatter(formatter)\n",
    "        logger.addHandler(fh)\n",
    "    return logger\n",
    "\n",
    "\n",
    "logger = setup_logger()\n",
    "\n",
    "\n",
    "class SummaryWriter:\n",
    "    def __init__(self, nb_epochs: int, nb_batchs: int) -> None:\n",
    "        self.nb_epochs = nb_epochs\n",
    "        self.nb_batchs = nb_batchs\n",
    "        self.epoch = 0\n",
    "\n",
    "    def set_epoch(self, epoch: int) -> None:\n",
    "        self.epoch = epoch\n",
    "\n",
    "    def __call__(self, mode: str, i_batch: int, metrics: Dict[str, float]) -> None:\n",
    "        summary = f\"{mode.title()} Epoch {self.epoch}/{self.nb_epochs} | Batch {i_batch}/{self.nb_batchs} | \"\n",
    "        for metric_name, metric_value in metrics.items():\n",
    "            summary += f\"{metric_name.title()} {metric_value:.2f} | \"\n",
    "        logger.info(summary[:-2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def calculate_accuracy(logits: torch.Tensor, y: torch.Tensor) -> float:\n",
    "    y_pred = torch.argmax(logits, dim=1)\n",
    "    return torch.mean((y_pred == y).float()).item()\n",
    "\n",
    "\n",
    "def pass_epoch(\n",
    "    loader: DataLoader,\n",
    "    backbone: nn.Module,\n",
    "    angular_margin: nn.Module,\n",
    "    optimizer: optim.Optimizer,\n",
    "    loss_fn: nn.Module,\n",
    "    summary_writer: SummaryWriter,\n",
    "    log_interval: int,\n",
    "    device: str,\n",
    ") -> Tuple[float]:\n",
    "\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    with torch.set_grad_enabled(backbone.training):\n",
    "        for i_batch, (x, y) in enumerate(loader):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            embeddings = backbone(x)\n",
    "            logits = angular_margin(embeddings, y)\n",
    "\n",
    "            loss_batch = loss_fn(logits, y)\n",
    "            acc_batch = calculate_accuracy(logits, y)\n",
    "\n",
    "            if backbone.training:\n",
    "                optimizer.zero_grad()\n",
    "                loss_batch.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            loss_batch = loss_batch.item()\n",
    "            if i_batch % log_interval == 0:\n",
    "                mode = \"train\" if backbone.training else \"validation\"\n",
    "                summary_writer(mode, i_batch, {\"loss\": loss_batch, \"acc\": acc_batch})\n",
    "\n",
    "            loss += loss_batch\n",
    "            acc += acc_batch\n",
    "\n",
    "    loss /= i_batch + 1\n",
    "    acc /= i_batch + 1\n",
    "    return loss, acc\n",
    "\n",
    "\n",
    "def train(\n",
    "    train_loader: DataLoader,\n",
    "    validation_loader: DataLoader,\n",
    "    angular_margin: nn.Module,\n",
    "    loss_fn: nn.Module,\n",
    "    feature_size: int,\n",
    "    lr: float,\n",
    "    nb_epochs: int,\n",
    "    log_interval: int,\n",
    "    early_stop_after: int,\n",
    "    device: str,\n",
    ") -> nn.Module:\n",
    "\n",
    "    backbone = EfficientNetBackbone(feature_size)\n",
    "    backbone.to(device)\n",
    "    angular_margin.to(device)\n",
    "\n",
    "    backbone_state_dict = backbone.state_dict()\n",
    "    head_state_dict = angular_margin.state_dict()\n",
    "\n",
    "    optimizer = optim.Adam(list(backbone.parameters()) + list(angular_margin.parameters()), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5)\n",
    "\n",
    "    summary_writer = SummaryWriter(nb_epochs, len(train_loader))\n",
    "\n",
    "\n",
    "    min_loss = math.inf\n",
    "    for epoch in range(nb_epochs):\n",
    "        summary_writer.set_epoch(epoch + 1)\n",
    "\n",
    "        backbone.train()\n",
    "        angular_margin.train()\n",
    "\n",
    "        loss, acc = pass_epoch(\n",
    "            train_loader,\n",
    "            backbone,\n",
    "            angular_margin,\n",
    "            optimizer,\n",
    "            loss_fn,\n",
    "            summary_writer,\n",
    "            log_interval,\n",
    "            device,\n",
    "        )\n",
    "        logger.info(f\"Train Epoch Loss: {loss:.2f} | Accuracy: {acc:.2f}\\n\")\n",
    "\n",
    "        backbone.eval()\n",
    "        angular_margin.eval()\n",
    "        loss, acc = pass_epoch(\n",
    "            validation_loader,\n",
    "            backbone,\n",
    "            angular_margin,\n",
    "            optimizer,\n",
    "            loss_fn,\n",
    "            summary_writer,\n",
    "            log_interval,\n",
    "            device,\n",
    "        )\n",
    "        acc = round(acc, 2)\n",
    "        logger.info(f\"Validation Epoch Loss: {loss:.2f} | Accuracy: {acc}\\n\")\n",
    "\n",
    "        if loss > min_loss:\n",
    "            min_loss = loss\n",
    "            early_stop_counter = 0\n",
    "            backbone_state_dict = backbone.state_dict()\n",
    "            head_state_dict = angular_margin.state_dict()\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "\n",
    "        if early_stop_counter == early_stop_after:\n",
    "            break\n",
    "\n",
    "        scheduler.step(loss)\n",
    "\n",
    "    backbone.load_state_dict(backbone_state_dict)\n",
    "    angular_margin.load_state_dict(head_state_dict)\n",
    "    return backbone, angular_margin, min_loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_embeddings(\n",
    "    experiment_name: str, test_loader: DataLoader, backbone: nn.Module, device: str\n",
    ") -> Tuple[np.ndarray]:\n",
    "    logger.info(f\"Extracting embeddings with the model with: {experiment_name}\")\n",
    "    log_interval = len(test_loader) // 5\n",
    "    test_embeddings = []\n",
    "\n",
    "    backbone.eval()\n",
    "    for i_batch, x in enumerate(test_loader):\n",
    "        x = x.to(device)\n",
    "\n",
    "        test_embeddings.append(backbone(x))\n",
    "\n",
    "        if i_batch % log_interval == 0:\n",
    "            logger.info(f\"Extracting embedings Batch {i_batch}/{len(test_loader)}\")\n",
    "\n",
    "    return torch.cat(test_embeddings).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((512, 512)),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485 * 255, 0.456 * 255, 0.406 * 255],\n",
    "            std=[0.229 * 255, 0.224 * 255, 0.225 * 255],\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path(folder, image_id):\n",
    "    return os.path.join(folder, f\"{image_id[0]}/{image_id[1]}/{image_id[2]}/{image_id}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class GoogleLandmarkDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        landmarks = sorted(list(set(self.img_labels[\"landmark_id\"])))\n",
    "        self.landmark_id_to_label = {landmarks[i]: i for i in range(len(landmarks))}\n",
    "        self.img_dir = img_dir\n",
    "        self.num_classes = len(landmarks)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = get_path(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = cv.imread(img_path)\n",
    "        label = self.landmark_id_to_label[self.img_labels.iloc[idx, 1]]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "dataset = GoogleLandmarkDataset(\n",
    "    img_dir=\"./data/train\",\n",
    "    annotations_file=\"./data/train.csv\",\n",
    "    transform=transformations,\n",
    ")\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "\n",
    "train_dataset, validation_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=0,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "validation_loader = DataLoader(\n",
    "    validation_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-17 09:46:03,643 | Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Head parameters\n",
    "m = 0.5  # For all\n",
    "s = 64  # For all\n",
    "alpha = 0.99  # For CurricularFace\n",
    "t = 1.2  # For MV-Arc-Softmax\n",
    "\n",
    "nb_epochs = 50\n",
    "lr = 1e-3\n",
    "early_stop_after = 11\n",
    "feature_size = 512  # Embeddings size\n",
    "log_interval = 50\n",
    "\n",
    "nb_classes = dataset.num_classes\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "logger.info(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone, head, acc = train(\n",
    "    train_loader,\n",
    "    validation_loader,\n",
    "    ArcFace(feature_size, nb_classes, s, m),\n",
    "    nn.CrossEntropyLoss(),\n",
    "    feature_size,\n",
    "    lr,\n",
    "    10,\n",
    "    1,\n",
    "    early_stop_after,\n",
    "    device,\n",
    ")\n",
    "\n",
    "plt.figure(num=None, figsize=(15, 15), dpi=80, facecolor=\"w\", edgecolor=\"k\")\n",
    "plt.plot(head.ts)\n",
    "plt.title(\"t values during training in CurricularFace\")\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"t\")\n",
    "logger.info(60 * \"-\" + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
