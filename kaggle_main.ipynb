{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding of the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATASET_PATH = \"\"\n",
    "NUM_WORKERS = 8\n",
    "BATCH_SIZE = 128\n",
    "IMAGE_SIZE = (224, 224)\n",
    "MODEL_PATH = \"\"\n",
    "EFFICIENT_NET_MODEL = \"efficientnet-b0\"\n",
    "FEATURE_SIZE = 512\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path(folder, image_id):\n",
    "    return os.path.join(folder, f\"{image_id[0]}/{image_id[1]}/{image_id[2]}/{image_id}.jpg\")\n",
    "\n",
    "def get_id(image_path):\n",
    "    return os.path.splitext(os.path.basename(image_path))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LandmarkDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.img_paths = glob.glob(os.path.join(img_dir, \"*/*/*/*.jpg\"))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        img_path = self.img_paths[idx]\n",
    "        image = read_image(img_path).float()\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, get_id(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485 * 255, 0.456 * 255, 0.406 * 255],\n",
    "            std=[0.229 * 255, 0.224 * 255, 0.225 * 255],\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = LandmarkDataset(TEST_DATASET_PATH, transformations)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class EfficientNetBackbone(nn.Module):\n",
    "    def __init__(self, feature_size: int, efficientNet: nn.Module):\n",
    "        super(EfficientNetBackbone, self).__init__()\n",
    "\n",
    "        self.efficientNet = efficientNet\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.efficientNet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def extract_embeddings(\n",
    "    test_loader: DataLoader, backbone: nn.Module, device: str\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    log_interval = len(test_loader) // 10\n",
    "    test_embeddings = []\n",
    "    test_ids = []\n",
    "\n",
    "    backbone.eval()\n",
    "    for i_batch, (x, y) in enumerate(test_loader):\n",
    "        x = x.to(device)\n",
    "\n",
    "        test_embeddings.append(backbone(x))\n",
    "        test_ids += y\n",
    "\n",
    "        if i_batch % log_interval == 0:\n",
    "            print(f\"Extracting embedings Batch {i_batch}/{len(test_loader)}\")\n",
    "\n",
    "    return torch.cat(test_embeddings).cpu().numpy(), np.array(test_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet = EfficientNet.from_name(EFFICIENT_NET_MODEL)\n",
    "\n",
    "backbone = EfficientNetBackbone(feature_size=FEATURE_SIZE, efficientNet=efficientnet)\n",
    "\n",
    "model_save = torch.load(MODEL_PATH)\n",
    "backbone.load_state_dict(model_save[\"backbone_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings, test_ids = extract_embeddings(test_loader, backbone, DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_EMBEDDINGS_PATH = \"index_embeddings.npy\"\n",
    "INDEX_IDS_PATH = \"index_ids.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_embeddings = np.load(INDEX_EMBEDDINGS_PATH)\n",
    "index_ids = np.load(INDEX_IDS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_neighbors(index_ids, query_ids, index_embeddings, query_embeddings):\n",
    "\n",
    "    similarities = cosine_similarity(query_embeddings, index_embeddings)\n",
    "\n",
    "    results = {\"id\": [], \"images\": []}\n",
    "\n",
    "    for i, query_id in enumerate(query_ids):\n",
    "        results[\"id\"].append(query_id)\n",
    "        results[\"images\"].append(\" \".join(index_ids[np.argsort(similarities[i])[-100:][::-1]]))\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = find_best_neighbors(index_ids, test_ids, index_embeddings, test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(results).to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
